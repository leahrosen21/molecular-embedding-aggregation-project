{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0kFytMB1c12"
      },
      "source": [
        "### $\\textbf{Installing and importing required packages}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuAr-uioe_vy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "installing compatible versions of required libraries.\n",
        "We pin transformers to <5.1.0 because as of 2026.01,\n",
        "MoLFormer (ibm/MoLFormer-XL-both-10pct) relies on\n",
        "internal modules such as transformers.onnx and remote\n",
        "configuration code that are not fully compatible with\n",
        "Transformers >=5.1.0. installing torch and onnx ensures\n",
        "model loading and ONNX-related utilities work correctly.\n",
        "Runtime version should be 2026.01 if running on Colab.\n",
        "'''\n",
        "\n",
        "\n",
        "%pip install -q \\\n",
        "    \"transformers<5.1.0\" \\\n",
        "    datasets \\\n",
        "    evaluate \\\n",
        "    wandb \\\n",
        "    peft \\\n",
        "    accelerate \\\n",
        "    umap-learn \\\n",
        "    onnx \\\n",
        "    rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u6z1GOj_ZCfP"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import Draw\n",
        "import pandas as pd\n",
        "\n",
        "#-------------------------------------------------------------------------#\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.special import softmax\n",
        "import evaluate\n",
        "from transformers.activations import ACT2FN\n",
        "from transformers import AutoModel, AutoConfig\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "#from peft import LoraConfig, get_peft_model\n",
        "\n",
        "#-------------------------------------------------------------------------#\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "#-------------------------------------------------------------------------#\n",
        "\n",
        "from google.colab import files, drive\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------#\n",
        "\n",
        "from transformers import TrainingArguments, Trainer, AutoTokenizer\n",
        "\n",
        "#-------------------------------------------------------------------------#\n",
        "from datasets import load_dataset\n",
        "#-------------------------------------------------------------------------#\n",
        "from torch.nn.functional import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "#-------------------------------------------------------------------------#\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        ")\n",
        "#-------------------------------------------------------------------------#\n",
        "import shutil\n",
        "#-------------------------------------------------------------------------#\n",
        "import umap\n",
        "#-------------------------------------------------------------------------#\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6RPTOHhZImp"
      },
      "outputs": [],
      "source": [
        "# requires an existing account in wandb. We used a designated API key\n",
        "# for privacy measures, we did not disclose our API key\n",
        "\n",
        "wandb.login(key=\"API-KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--A-t0q21lmY"
      },
      "source": [
        "### $\\textbf{Validating RDKit installation}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKXXfLqy1sDD"
      },
      "outputs": [],
      "source": [
        "# Two different ways to write the SMILES for Aspirin\n",
        "smiles_1 = \"CC(=O)OC1=CC=CC=C1C(=O)O\"\n",
        "smiles_2 = \"O=C(O)c1ccccc1OC(=O)C\"\n",
        "\n",
        "# converting to RDKit Molecule objects\n",
        "mol1 = Chem.MolFromSmiles(smiles_1)\n",
        "mol2 = Chem.MolFromSmiles(smiles_2)\n",
        "\n",
        "# getting the Canonical SMILES\n",
        "can_smiles_1 = Chem.MolToSmiles(mol1)\n",
        "can_smiles_2 = Chem.MolToSmiles(mol2)\n",
        "\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "df = pd.DataFrame(columns=['Smiles', 'Canonical Smiles'])\n",
        "df.loc[len(df)] = [smiles_1, can_smiles_1]\n",
        "df.loc[len(df)] = [smiles_2, can_smiles_2]\n",
        "print(df)\n",
        "print()\n",
        "\n",
        "# visualizing them\n",
        "Draw.MolsToGridImage([mol1, mol2], legends=['Version A', 'Version B'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nJKhx7w1ve5"
      },
      "source": [
        "### $\\textbf{Setting up required classes for extension approaches}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPsAkKcfZd98"
      },
      "outputs": [],
      "source": [
        "# The Classification Head Class in Molformer's repository. Will be used in a custom class.\n",
        "# the attribute \"num_labels\" was added for execution\n",
        "# https://huggingface.co/ibm-research/MoLFormer-XL-both-10pct/blob/main/modeling_molformer.py\n",
        "\n",
        "class MolformerClassificationHead(nn.Module):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dense2 = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dropout = nn.Dropout(\n",
        "            config.classifier_dropout_prob\n",
        "            if config.classifier_dropout_prob is not None\n",
        "            else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.out_proj = nn.Linear(config.hidden_size, num_labels)\n",
        "        self.classifier_act_fn = ACT2FN[config.hidden_act]\n",
        "        self.skip_connection = config.classifier_skip_connection\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        hidden_state = self.dense(pooled_output)\n",
        "        hidden_state = self.dropout(hidden_state)\n",
        "        hidden_state = self.classifier_act_fn(hidden_state)\n",
        "        if self.skip_connection:\n",
        "            hidden_state = residual = hidden_state + pooled_output\n",
        "        hidden_state = self.dense2(hidden_state)\n",
        "        hidden_state = self.dropout(hidden_state)\n",
        "        hidden_state = self.classifier_act_fn(hidden_state)\n",
        "        if self.skip_connection:\n",
        "            hidden_state = hidden_state + residual\n",
        "        return self.out_proj(hidden_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LOViJ1OZfMr"
      },
      "outputs": [],
      "source": [
        "class SMILESDataset(Dataset):\n",
        "\n",
        "    '''\n",
        "    This is a custom PyTorch Dataset designed to handle\n",
        "    molecular data represented by SMILES (Simplified\n",
        "    Molecular Input Line Entry System) strings. It is\n",
        "    specifically tailored for tasks involving sequence\n",
        "    classification or regression using models like MoLFormer.\n",
        "\n",
        "    Upon initialization, the dataset canonicalizes all\n",
        "    SMILES strings using RDKit. This ensures that each\n",
        "    molecule has a unique and standardized representation,\n",
        "    which is crucial for consistent model training. It\n",
        "    handles invalid or unparsable SMILES strings by\n",
        "    filtering them out, preventing errors during downstream\n",
        "    processing.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, df, tokenizer, label_column=\"label\", task_type=\"cls\"):\n",
        "        processed_data = []\n",
        "\n",
        "        # processing only valid and acceptable smiles sequences,\n",
        "        # otherwise they produce NaN values in predictions\n",
        "        for _, row in df.iterrows():\n",
        "            smiles = self.canonicalize(row['smiles'])\n",
        "            if smiles is not None:\n",
        "                processed_data.append({\n",
        "                    \"smiles\": smiles,\n",
        "                    \"label\": row[label_column]\n",
        "                  })\n",
        "\n",
        "        self.smiles_list = [item['smiles'] for item in processed_data]\n",
        "        self.labels = [item['label'] for item in processed_data]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = 202 # fixed max length that matches the MoLFormer model\n",
        "        self.task_type = task_type # Store task_type\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    # https://github.com/IBM/molformer/blob/main/notebooks/pretrained_molformer/frozen_embeddings_classification.ipynb\n",
        "    def canonicalize(self, s):\n",
        "        mol = Chem.MolFromSmiles(s) # getting the molecule from smiles sequence\n",
        "        if mol is not None:\n",
        "            return Chem.MolToSmiles(mol, canonical=True, isomericSmiles=True) # after canonicalization - returning to smiles sequence\n",
        "        return None # Returning None if RDKit fails to parse the SMILES\n",
        "\n",
        "\n",
        "    def get_num_classes(self):\n",
        "      # For regression, num_labels is 1. For classification, it's the number of unique labels.\n",
        "      return len(set(self.labels)) if self.task_type == \"cls\" else 1\n",
        "\n",
        "\n",
        "    def get_length_stats(self, mode=\"effective\"):\n",
        "        '''\n",
        "         mode:\n",
        "         'true': tokenized length without truncation/padding\n",
        "         'effective': non-padding tokens after truncation\n",
        "        '''\n",
        "\n",
        "        if not self.smiles_list:\n",
        "            return 0.0, 0, 0\n",
        "\n",
        "        lengths = []\n",
        "\n",
        "        if mode == \"true\":\n",
        "            for smiles in self.smiles_list:\n",
        "                lengths.append(\n",
        "                    len(self.tokenizer(smiles, padding=False, truncation=False)[\"input_ids\"])\n",
        "                )\n",
        "\n",
        "        elif mode == \"effective\":\n",
        "            for i in range(len(self.smiles_list)):\n",
        "              item = self.__getitem__(i)\n",
        "              attention_mask = item['attention_mask']\n",
        "              lengths.append(\n",
        "                    attention_mask.sum().item()\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        avg = sum(lengths) / len(lengths)\n",
        "        max_length = max(lengths)\n",
        "        min_length = min(lengths)\n",
        "\n",
        "        return avg, max_length, min_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # This converts a SMILES string into a list of numbers (tokens)\n",
        "        smiles = self.smiles_list[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        inputs = self.tokenizer(smiles,\n",
        "                                  truncation=True,\n",
        "                                  padding=\"max_length\",\n",
        "                                  max_length=self.max_length,\n",
        "                                  return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "\n",
        "        # for best practices, we ensure required data types\n",
        "        if self.task_type == \"reg\":\n",
        "            labels = torch.tensor(label, dtype=torch.float)\n",
        "        else:\n",
        "            labels = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels # the column name as required by the hugging face API\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK3WfgYRZhen"
      },
      "outputs": [],
      "source": [
        "class CustomModelForSequenceClassification(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    This class is a custom PyTorch nn.Module designed\n",
        "    to adapt the pre-trained MoLFormer encoder\n",
        "    for sequence classification or regression tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "        # Pass num_labels to the classification head\n",
        "        self.num_labels = num_labels\n",
        "        self.classifier = MolformerClassificationHead(self.encoder.config, num_labels)\n",
        "\n",
        "\n",
        "        if self.num_labels == 1:\n",
        "            self.loss_fn = nn.MSELoss()\n",
        "        elif self.num_labels == 2:\n",
        "            self.loss_fn = nn.CrossEntropyLoss()\n",
        "        else: # for multi-label classification, adapted from the MoLFormer's code on HF.\n",
        "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "            # we did not conduct experiments on multi-label classification, this is never used\n",
        "            # possible future direction - to extend to multi-label classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask)\n",
        "\n",
        "        # take first token in the sequence for all items in the batch\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        logits = self.classifier(cls_embeddings)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1: # reshaping labels for regression to (batch_size, 1)\n",
        "                labels = labels.view(-1, 1).float()\n",
        "            if self.num_labels > 2: # for multi-label classification\n",
        "                labels = labels.float()\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwMKAA5R4b3w"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "------------------------------------------------------------------\n",
        "Preliminary PEFT Experiment: LoRA Fine-Tuning on MoLFormer\n",
        "\n",
        "As an exploratory extension of our work, we implemented a parameter-\n",
        "efficient fine-tuning (PEFT) approach using LoRA (Low-Rank Adaptation)\n",
        "on top of the MoLFormer backbone.\n",
        "\n",
        "In this setup, LoRA adapters are injected into the transformer attention\n",
        "layers (query and value projections), while a custom classification head\n",
        "is trained on top of the CLS token representation.\n",
        "\n",
        "This experiment is still preliminary and was not fully optimized or\n",
        "systematically evaluated. However, we include it here as a potential\n",
        "direction for future research on efficient molecular representation\n",
        "fine-tuning using MoLFormer\n",
        "------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class LoraMoLFormer(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, lora_r=8, lora_alpha=16):\n",
        "        super().__init__()\n",
        "\n",
        "        # Loading the base (foundation) Model\n",
        "        self.base_model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "        self.base_model.config.num_labels = num_labels\n",
        "\n",
        "        # Configuring LoRA, either with input or default values\n",
        "        peft_config = LoraConfig(\n",
        "            task_type=None, # We are using a custom head, so we manage the task manually\n",
        "            r=lora_r,\n",
        "            lora_alpha=lora_alpha,\n",
        "            target_modules=[\"query\", \"value\"], # Standard for transformer LoRA\n",
        "            lora_dropout=0.1,\n",
        "            bias=\"none\"\n",
        "        )\n",
        "\n",
        "        self.peft_model = get_peft_model(self.base_model, peft_config)\n",
        "\n",
        "\n",
        "        self.custom_head = MolformerClassificationHead(self.base_model.config, num_labels)\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        # Pass inputs to the Base Model\n",
        "        outputs = self.peft_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the CLS token representation (the \"summary\" of the molecule)\n",
        "        # MoLFormer uses the first token [0] for this.\n",
        "        molecule_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Pass the embedding through your custom head\n",
        "        logits = self.custom_head(molecule_embedding)\n",
        "\n",
        "        # Calculate loss manually so the Trainer doesn't crash\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        # Return everything in a format the Hugging Face Trainer understands\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits\n",
        "        )\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9yh7WAv5gaT"
      },
      "source": [
        "### $\\textbf{Loading and creating the datasets}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FdJUmDTzj-m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# if files are loaded from google drive, use this and follow the instructions that pop up\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlyHOg0LzmkE"
      },
      "outputs": [],
      "source": [
        "# https://moleculenet.org/datasets-1\n",
        "\n",
        "def load_datasets(task_type, model_name=None, tokenizer=None, datasets_folder=None):\n",
        "\n",
        "    '''\n",
        "    Loads datasets from a specified folder, processes them\n",
        "    using a tokenizer, and returns a dictionary of\n",
        "    SMILESDataset instances.\n",
        "    '''\n",
        "\n",
        "    if datasets_folder is None:\n",
        "        datasets_folder = f\"/content/drive/MyDrive/deep-learning-final-project/{task_type}\"\n",
        "\n",
        "    # this code is intended for the MoLFormer model, but for modularity,\n",
        "    # we allow passing a custom tokenizer and model ID\n",
        "\n",
        "    # if no tokenizer is provided, load the default one based on the model ID\n",
        "    if tokenizer is None:\n",
        "        if model_name is None:\n",
        "            model_name = \"ibm/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "    dataframes = {}\n",
        "    datasets = {}\n",
        "\n",
        "    # looping through all CSV files in the folder\n",
        "    for filename in os.listdir(datasets_folder):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            name = filename.replace(\".csv\", \"\")\n",
        "            file_path = os.path.join(datasets_folder, filename)\n",
        "\n",
        "            print(f\"Loaded: {name}\")\n",
        "\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "            except UnicodeDecodeError:\n",
        "                df = pd.read_csv(file_path, encoding='latin1') # a fallback encoding if the file can't be read (only used for the bbbp files)\n",
        "\n",
        "            dataframes[name] = df\n",
        "            datasets[name] = SMILESDataset(df, tokenizer, task_type=task_type)\n",
        "\n",
        "    return datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnvTYtOUwueJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "#------if files are loaded locally on to google colab and not from google drive, use the following code.------#\n",
        "\n",
        "# https://moleculenet.org/datasets-1\n",
        "\n",
        "def load_datasets(task_type, model_name=None, tokenizer=None):\n",
        "\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  dataframes = {}\n",
        "  datasets = {}\n",
        "\n",
        "     # if no tokenizer is provided, load the default one based on the model ID\n",
        "  if tokenizer is None:\n",
        "      if model_name is None:\n",
        "          model_name = \"ibm/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "      tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "  for filename in uploaded.keys():\n",
        "      name = filename.replace(\".csv\", \"\")  # e.g. bace_train\n",
        "      print(f\"Loaded: {name}\")\n",
        "\n",
        "      # Try reading with 'latin1' encoding to resolve UnicodeDecodeError\n",
        "      try:\n",
        "          df = pd.read_csv(filename)\n",
        "      except UnicodeDecodeError:\n",
        "          df = pd.read_csv(filename, encoding='latin1') # a fallback encoding if the file can't be read (only used for the bbbp files)\n",
        "\n",
        "      dataframes[name] = df\n",
        "      datasets[name] = SMILESDataset(df, tokenizer, task_type=task_type)\n",
        "\n",
        "  return datasets\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mR3e5Y4XZ1D_"
      },
      "outputs": [],
      "source": [
        "# loading datasets for classification tasks\n",
        "\n",
        "cls_datasets = load_datasets(\"cls\")\n",
        "cls_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FbHa4ptZ2_7"
      },
      "outputs": [],
      "source": [
        "# CLASSIFICATION TASKS DATASETS\n",
        "\n",
        "bace_train = cls_datasets['bace_train']\n",
        "bace_test = cls_datasets['bace_test']\n",
        "bace_eval = cls_datasets['bace_valid']\n",
        "\n",
        "bbbp_train = cls_datasets['bbbp_train']\n",
        "bbbp_test = cls_datasets['bbbp_test']\n",
        "bbbp_eval = cls_datasets['bbbp_valid']\n",
        "\n",
        "clintox_train = cls_datasets['clintox_train']\n",
        "clintox_test = cls_datasets['clintox_test']\n",
        "clintox_eval = cls_datasets['clintox_valid']\n",
        "\n",
        "'''\n",
        "we wanted to use the hiv dataset, however it was signficantly\n",
        "larger than the rest of the datasets (~33K samples) Therefore,\n",
        "training took longer and we wanted to keep the training datasets\n",
        "as balanced as we can in terms of size.\n",
        "\n",
        "# hiv_train = datasets['hiv_train']\n",
        "# hiv_test = datasets['hiv_test']\n",
        "# hiv_eval = datasets['hiv_valid']\n",
        "'''\n",
        "\n",
        "\n",
        "cls_datasets = {\n",
        "    \"BBBP\": {\"train\": bbbp_train,\n",
        "             \"eval\": bbbp_eval,\n",
        "             \"test\": bbbp_test},\n",
        "\n",
        "    \"BACE\": {\"train\": bace_train,\n",
        "             \"eval\": bace_eval,\n",
        "             \"test\": bace_test},\n",
        "\n",
        "    \"CLINTOX\": {\"train\": clintox_train,\n",
        "                \"eval\": clintox_eval,\n",
        "                \"test\": clintox_test},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rplBSDoD_oua"
      },
      "outputs": [],
      "source": [
        "# loading datasets for regression tasks\n",
        "\n",
        "reg_datasets = load_datasets(\"reg\")\n",
        "reg_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rsOJm1A-qcv"
      },
      "outputs": [],
      "source": [
        "# REGRESSION TASKS DATASETS\n",
        "\n",
        "lipo_train = reg_datasets['lipo_train']\n",
        "lipo_test = reg_datasets['lipo_test']\n",
        "lipo_eval = reg_datasets['lipo_valid']\n",
        "\n",
        "esol_train = reg_datasets['esol_train']\n",
        "esol_test = reg_datasets['esol_test']\n",
        "esol_eval = reg_datasets['esol_valid']\n",
        "\n",
        "freesolv_train = reg_datasets['freesolv_train']\n",
        "freesolv_test = reg_datasets['freesolv_test']\n",
        "freesolv_eval = reg_datasets['freesolv_valid']\n",
        "\n",
        "\n",
        "reg_datasets = {\n",
        "    \"LIPO\": {\"train\": lipo_train,\n",
        "             \"eval\": lipo_eval,\n",
        "             \"test\": lipo_test},\n",
        "\n",
        "    \"ESOL\": {\"train\": esol_train,\n",
        "             \"eval\": esol_eval,\n",
        "             \"test\": esol_test},\n",
        "\n",
        "    \"FreeSolv\": {\"train\": freesolv_train,\n",
        "                 \"eval\": freesolv_eval,\n",
        "                 \"test\": freesolv_test},\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5SlIdyX5w9Q"
      },
      "source": [
        "### $\\textbf{Motivation through toy example: Visualization of Pooled Embedding vs. First Token Embedding ([CLS], <bos>)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kKv99O5oxZRV"
      },
      "outputs": [],
      "source": [
        "# loading a common dataset for Chemistry property prediction task (ESol)\n",
        "dataset = load_dataset(\"gayane/esol\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKHCMoSeA2r9"
      },
      "outputs": [],
      "source": [
        "toy_df = pd.DataFrame(dataset['train']) # extracting the training molecular sequences\n",
        "\n",
        "'''\n",
        "SMILES (Simplified Molecular Input Line Entry System)\n",
        "is a way to represent chemical structures using a single\n",
        "line of text. The problem is that a single molecule can\n",
        "often be written in many different \"correct\" ways.\n",
        "Canonicalization means to pick exactly one unique version\n",
        "of that string to be the \"standard\" (or \"canonical\") name.\n",
        "Once a SMILES string is canonicalized, it acts like a\n",
        "\"fingerprint\" or a unique ID for that specific molecule.\n",
        "'''\n",
        "\n",
        "toy_df['smiles'] = toy_df['smiles'].apply(lambda x: Chem.MolToSmiles(Chem.MolFromSmiles(x), canonical=True, isomericSmiles=True))\n",
        "toy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "joK24sc-A5oc"
      },
      "outputs": [],
      "source": [
        "# loading the Molformer foundation model\n",
        "model_name = \"ibm-research/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name, deterministic_eval=True, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "smiles_list = toy_df['smiles'].tolist()\n",
        "\n",
        "# tokenizing the sequences\n",
        "inputs = tokenizer(smiles_list, padding=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuEBFp1WA8bW"
      },
      "outputs": [],
      "source": [
        "# getting inference *token-level* contextual embeddings for toy dataset sequences\n",
        "with torch.no_grad():\n",
        "    out = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbu-5lxMA_RQ"
      },
      "outputs": [],
      "source": [
        "# calculating cosine similarity between the pooled output\n",
        "# and the first token embedding in the sequence\n",
        "\n",
        "# Calculating all cosine similarities and storing them\n",
        "cosine_similarities = []\n",
        "pooled_embs = []\n",
        "first_token_embs = []\n",
        "\n",
        "for i in range(len(toy_df)):\n",
        "    pooled_embedding = out.pooler_output[i].unsqueeze(0) # the pooled embedding\n",
        "    first_token_embedding = out.last_hidden_state[i][0].unsqueeze(0) # cls token embedding\n",
        "    pooled_embs.append(pooled_embedding)\n",
        "    first_token_embs.append(first_token_embedding)\n",
        "\n",
        "    similarity = torch.nn.functional.cosine_similarity(pooled_embedding, first_token_embedding)\n",
        "    cosine_similarities.append(similarity.item())\n",
        "\n",
        "# converting to a PyTorch tensor for easier statistical operations\n",
        "cosine_similarities_tensor = torch.tensor(cosine_similarities)\n",
        "\n",
        "# printing descriptive statistics\n",
        "print(f\"\\nDescriptive Statistics for Cosine Similarities:\")\n",
        "print(f\"Average Cosine Similarity: {torch.mean(cosine_similarities_tensor):.4f}\")\n",
        "print(f\"Minimum Cosine Similarity: {torch.min(cosine_similarities_tensor):.4f}\")\n",
        "print(f\"Maximum Cosine Similarity: {torch.max(cosine_similarities_tensor):.4f}\")\n",
        "print(f\"Standard Deviation: {torch.std(cosine_similarities_tensor):.4f}\")\n",
        "print()\n",
        "\n",
        "# plotting a histogram of the cosine similarities\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(cosine_similarities, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.title('Distribution of Cosine Similarities Between Pooled Output and First Token Embedding')\n",
        "plt.xlabel('Cosine Similarity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUEcSllntiVM"
      },
      "outputs": [],
      "source": [
        "# performing UMAP to compare embeddings of the first token and the pooled one\n",
        "# code inspired by the practical notebooks in the Deep Learning course\n",
        "\n",
        "pooled_embs_tensor = torch.cat(pooled_embs, dim=0) # tensor for pooled embeddings\n",
        "first_token_embs_tensor = torch.cat(first_token_embs, dim=0) # tensor for cls token embeddings\n",
        "combined_embeddings = torch.cat((pooled_embs_tensor, first_token_embs_tensor), dim=0) # combined tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfgwirzstvyX"
      },
      "outputs": [],
      "source": [
        "\n",
        "pooled_embs_np = pooled_embs_tensor.cpu().numpy()\n",
        "first_token_embs_np = first_token_embs_tensor.cpu().numpy()\n",
        "combined_embeddings_np = combined_embeddings.cpu().numpy()\n",
        "\n",
        "# initializing UMAP reducer\n",
        "umap_reducer_2d = umap.UMAP(n_components=2,\n",
        "                            min_dist=0.0,\n",
        "                            metric='cosine',\n",
        "                            random_state=42)\n",
        "\n",
        "# fitting and transforming the data\n",
        "umap_transformed_embeddings_2d = umap_reducer_2d.fit_transform(combined_embeddings_np)\n",
        "\n",
        "print(f\"Shape of umap_transformed_embeddings: {umap_transformed_embeddings_2d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTA6mOsDtx5y"
      },
      "outputs": [],
      "source": [
        "# separating the transformed embeddings back into pooled and first_token components for plotting\n",
        "half_size = len(toy_df)\n",
        "umap_pooled_output = umap_transformed_embeddings_2d[:half_size]\n",
        "umap_first_token_embeddings = umap_transformed_embeddings_2d[half_size:]\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(umap_pooled_output[:, 0], umap_pooled_output[:, 1], label='Pooled Output', alpha=0.7, s=10, color=\"maroon\")\n",
        "plt.scatter(umap_first_token_embeddings[:, 0], umap_first_token_embeddings[:, 1], label='First Token Embeddings', alpha=0.7, s=10)\n",
        "plt.title('UMAP of Pooled Output vs. First Token Embedding')\n",
        "plt.xlabel('UMAP Component 1')\n",
        "plt.ylabel('UMAP Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4u3-gnP6Jfj"
      },
      "source": [
        "### $\\textbf{Additional auxiliary functions and classes (that rely on the datasets)}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26bkK950x1MG"
      },
      "outputs": [],
      "source": [
        "# source: https://huggingface.co/docs/transformers/v5.0.0rc2/en/main_classes/trainer#transformers.TrainingArguments\n",
        "# source: https://www.manning.com/books/domain-specific-small-language-models\n",
        "\n",
        "def get_training_args(\n",
        "    output_dir,\n",
        "    task_type,  # \"reg\" or \"cls\"\n",
        "    best_metric,\n",
        "    config=None\n",
        "):\n",
        "    '''\n",
        "    Creates HuggingFace TrainingArguments with defaults\n",
        "    with the option to override specific hyperparameters\n",
        "    using a config dictionary.\n",
        "    - output_dir: the directory where the model checkpoints\n",
        "    and logs will be saved during training\n",
        "    - task_type: \"reg\" or \"cls\"\n",
        "    - best_metric: the metric to monitor for saving the best model\n",
        "    - config: a dictionary of hyperparameters to use for training\n",
        "    '''\n",
        "\n",
        "    # if no config is provided, we use an empty dictionary\n",
        "    if config is None:\n",
        "        config = {}\n",
        "\n",
        "    # using default config if values are not provided\n",
        "    train_batch_size = config.get(\"train_batch_size\", 64)\n",
        "    eval_batch_size = config.get(\"eval_batch_size\", 64)\n",
        "    num_train_epochs = config.get(\"num_train_epochs\", 10)\n",
        "    learning_rate = config.get(\"learning_rate\", 1e-5)  # MolFormer used 3e-5\n",
        "    weight_decay = config.get(\"weight_decay\", 0.01)\n",
        "    warmup_ratio = config.get(\"warmup_ratio\", 0.1)\n",
        "    max_grad_norm = config.get(\"max_grad_norm\", 1.0)\n",
        "    seed = config.get(\"seed\", 42)\n",
        "\n",
        "    # Regression - lower is better, Classification - higher is better\n",
        "    greater_is_better = task_type == \"cls\"\n",
        "\n",
        "    return TrainingArguments(\n",
        "\n",
        "        # the directory where the model checkpoints\n",
        "        # and logs will be saved during training\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=True,\n",
        "\n",
        "        # evaluation and saving strategy\n",
        "        # we evaluate and save the model\n",
        "        # at the end of each epoch\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "\n",
        "        load_best_model_at_end=True,\n",
        "        remove_unused_columns=False, # to avoid issues with the custom dataset and model\n",
        "\n",
        "        # the specific metric to monitor for saving the best model\n",
        "        metric_for_best_model=best_metric,\n",
        "        greater_is_better=greater_is_better,\n",
        "\n",
        "        # hyperparameters that can be overridden by the config dictionary\n",
        "        per_device_train_batch_size=train_batch_size,\n",
        "        per_device_eval_batch_size=eval_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        max_grad_norm=max_grad_norm,\n",
        "\n",
        "        # logging strategy to log training progress every epoch\n",
        "        logging_strategy=\"epoch\",\n",
        "        # logging_steps - if logging steps are desired\n",
        "\n",
        "        report_to=\"wandb\", # to enable logging to Weights & Biases\n",
        "        dataloader_num_workers=0,\n",
        "\n",
        "        # precision settings for training and evaluation\n",
        "        fp16=False,\n",
        "        fp16_full_eval=False,\n",
        "\n",
        "        save_safetensors=False, # to avoid issues with the custom model and Trainer\n",
        "        seed=seed\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aJc4tsHyM3b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "\n",
        "    '''\n",
        "    this function computes the metrics for regression\n",
        "    and classification tasks and returns a dictionary\n",
        "    of metrics for evaluation.\n",
        "    - pred: the predictions from the model\n",
        "    '''\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions\n",
        "\n",
        "    # metrics for REGRESSION\n",
        "    if preds.ndim == 1 or preds.shape[-1] == 1:\n",
        "        predictions = preds.reshape(-1)\n",
        "\n",
        "        # Safety check\n",
        "        if np.isnan(predictions).any() or np.isinf(predictions).any():\n",
        "            print(\"WARNING: NaN or Inf detected in regression predictions!\")\n",
        "            predictions = np.nan_to_num(predictions)\n",
        "\n",
        "        mse = mean_squared_error(labels, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(labels, predictions)\n",
        "        r2 = r2_score(labels, predictions)\n",
        "\n",
        "        return {\n",
        "            \"rmse\": rmse,\n",
        "            \"mse\": mse,\n",
        "            \"mae\": mae,\n",
        "            \"r2\": r2,\n",
        "        }\n",
        "\n",
        "    # metrics for BINARY CLASSIFICATION\n",
        "    elif preds.shape[-1] == 2:\n",
        "        logits = preds\n",
        "\n",
        "        # Safety check for logits before applying softmax\n",
        "        if np.isnan(logits).any() or np.isinf(logits).any():\n",
        "            print(\"WARNING: NaN or Inf detected in logits!\")\n",
        "            logits = np.nan_to_num(logits)\n",
        "\n",
        "        probs = softmax(logits, axis=-1)[:, 1]\n",
        "        preds_cls = (probs >= 0.5).astype(int)\n",
        "\n",
        "        # Safety check for probabilities after softmax\n",
        "        if np.isnan(probs).any() or np.isinf(probs).any():\n",
        "            print(\"WARNING: NaN or Inf detected in probabilities!\")\n",
        "            probs = np.nan_to_num(probs)\n",
        "\n",
        "        return {\n",
        "            \"roc_auc\": roc_auc_score(labels, probs),\n",
        "            \"pr_auc\": average_precision_score(labels, probs),\n",
        "            \"precision\": precision_score(labels, preds_cls, zero_division=0),\n",
        "            \"recall\": recall_score(labels, preds_cls, zero_division=0),\n",
        "            \"f1\": f1_score(labels, preds_cls, zero_division=0),\n",
        "            \"pos_rate\": preds_cls.mean(),\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported prediction shape: {preds.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qagqb3Fz6bz8"
      },
      "source": [
        "### $\\textbf{Hyperparameter functions and code}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqQnjmOXfU5d"
      },
      "outputs": [],
      "source": [
        "def _hp_search_core(config, task_name, task_datasets, model_name=None):\n",
        "    '''\n",
        "    This function is the core training loop for a single\n",
        "    hyperparameter sweep run. It will be called by a\n",
        "    wrapper function that handles wandb.init.\n",
        "    Logged with Weights&Biases\n",
        "\n",
        "    config: a dictionary of hyperparameters to use for training\n",
        "    task_name: the name of the task to train on (BBBP, BACE, etc.)\n",
        "    task_datasets: a dictionary containing the train, eval, and test datasets\n",
        "    model_name: the name of the model to use for training. If None,\n",
        "                the default model will be used. (MoLFormer)\n",
        "    '''\n",
        "\n",
        "    train_dataset = task_datasets[\"train\"]\n",
        "    eval_dataset = task_datasets[\"eval\"]\n",
        "    task_type = train_dataset.task_type\n",
        "    best_metric = \"roc_auc\" if task_type == \"cls\" else \"rmse\"\n",
        "\n",
        "    num_labels = train_dataset.get_num_classes()\n",
        "\n",
        "    # we repeat this as a safety net to make sure the model is specified\n",
        "    if model_name is None:\n",
        "        model_name = \"ibm/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "    model = CustomModelForSequenceClassification(model_name, num_labels)\n",
        "\n",
        "    # setting training arguments\n",
        "    training_args = get_training_args(\n",
        "        output_dir=f\"/content/molformer-hp-search/{task_name}\",\n",
        "        task_type=task_type,\n",
        "        best_metric=best_metric,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    # initializing trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBUb8uL5gsjQ"
      },
      "outputs": [],
      "source": [
        "def run_hp_search(tasks_to_run, sweep_config, num_trials=10, model_name=None):\n",
        "\n",
        "    '''\n",
        "    this function runs hyperparameter search for a list of tasks.\n",
        "\n",
        "    - tasks_to_run: a list of task names to run hyperparameter search for\n",
        "    - sweep_config: a dictionary of hyperparameters to use for training\n",
        "    - model_name: the name of the model to use for training (default: MoLFormer)\n",
        "    - num_trials: the number of trials to run for each task (default: 10)\n",
        "    '''\n",
        "\n",
        "    if model_name is None:\n",
        "        model_name = \"ibm/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "    for task_name, task_datasets in tasks_to_run.items():\n",
        "\n",
        "        project_name = f\"molformer-hp-search-{task_name}\"\n",
        "        sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
        "\n",
        "        '''\n",
        "        the wrapper function below facilitates the interaction\n",
        "        between wandb.agent and the custom training logic,\n",
        "        ensuring each trial runs with its unique configuration.\n",
        "        '''\n",
        "        def _task_sweep_wrapper():\n",
        "\n",
        "            # initializes a new W&B run\n",
        "            # corresponds to a new combination of hp\n",
        "            with wandb.init() as run:\n",
        "\n",
        "                # retrieves the specific hyperparameter\n",
        "                # values chosen by the W&B sweep for this particular run.\n",
        "                config = run.config\n",
        "\n",
        "                # calling the actual search logic\n",
        "                _hp_search_core(\n",
        "                    config=config,\n",
        "                    task_name=task_name,\n",
        "                    task_datasets=task_datasets,\n",
        "                    model_name=model_name\n",
        "                )\n",
        "\n",
        "\n",
        "        '''\n",
        "        the agent launches 'count' individual runs (trials)\n",
        "        per task. Each run will use a different set\n",
        "        of hyperparameters (sampled according to sweep_config)\n",
        "        and execute the _task_sweep_wrapper function.\n",
        "        '''\n",
        "\n",
        "        print(f\"Starting sweep for task: {task_name}\")\n",
        "        wandb.agent(sweep_id, function=_task_sweep_wrapper, count=num_trials)\n",
        "        print(f\"Sweep for task {task_name} completed.\")\n",
        "        print(\"-\" * 50)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8lZ33q0oTRl"
      },
      "outputs": [],
      "source": [
        "# adapted from https://wandb.ai/matt24/vit-snacks-sweeps/reports/Hyperparameter-Search-for-HuggingFace-Transformer-Models--VmlldzoyMTUxNTg0\n",
        "\n",
        "'''\n",
        "Weights & Biases Sweeps requires a configuration\n",
        "file to define the hyperparameters to explore,\n",
        "their range of values, the search strategy, etc.\n",
        "'''\n",
        "# randomly searching the different values of hyperparameters\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "}\n",
        "\n",
        "'''\n",
        "Note, MoLFormer's original hyperparameters were:\n",
        "    - batch_size 128\n",
        "    - d_dropout 0.1\n",
        "    - dropout 0.1\n",
        "    - lr_start 3e-5\n",
        "    - num_workers 8\n",
        "    - max_epochs 500\n",
        "\n",
        "    for more information, see the original repository:\n",
        "    https://github.com/IBM/molformer/tree/main/finetune\n",
        "'''\n",
        "# hyperparameters\n",
        "parameters_dict = {\n",
        "    'num_train_epochs': {\n",
        "        'value': 1\n",
        "    },\n",
        "\n",
        "    'train_batch_size': {\n",
        "        'values': [8, 16, 32, 64]\n",
        "    },\n",
        "\n",
        "    # the learning rate will be sampled log-uniformly\n",
        "    'learning_rate': {\n",
        "        'distribution': 'log_uniform_values',\n",
        "        'min': 1e-5,\n",
        "        'max': 3e-5\n",
        "    },\n",
        "\n",
        "    # adding a penalty to the loss function based\n",
        "    # on the magnitude of the model's weights.\n",
        "    'weight_decay': {\n",
        "        'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "    },\n",
        "\n",
        "    # warmup ratio for the learning rate\n",
        "    'warmup_ratio': {\n",
        "            'values': [0.0, 0.1, 0.2, 0.3]\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "'''\n",
        "we will explore the hyperparameter values for one\n",
        "epoch because later we will fine-tune for more\n",
        "epochs using some of the best combinations of\n",
        "values found with Sweeps\n",
        "'''\n",
        "\n",
        "# adding the parameters dictionary to the configuration\n",
        "sweep_config['parameters'] = parameters_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZYjEBA5PpTmd"
      },
      "outputs": [],
      "source": [
        "# running hyperparameter search for classification tasks\n",
        "\n",
        "run_hp_search(cls_datasets, sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "osf1Pik7qLWx"
      },
      "outputs": [],
      "source": [
        "# running hyperparameter search for regression tasks\n",
        "\n",
        "run_hp_search(reg_datasets, sweep_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMfIlm6e9KBl"
      },
      "source": [
        "### $\\textbf{Finetuning}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C1ic3aOe12l"
      },
      "outputs": [],
      "source": [
        "# setting configurations according to the hyperparameter search analysis for classification tasks\n",
        "\n",
        "cls_datasets[\"BBBP\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 2.91e-5,\n",
        "    \"weight_decay\": 0.3,\n",
        "    \"warmup_ratio\": 0.3\n",
        "    }\n",
        "\n",
        "cls_datasets[\"BACE\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 2.62e-5,\n",
        "    \"weight_decay\": 0.5,\n",
        "    \"warmup_ratio\": 0.1\n",
        "    }\n",
        "\n",
        "cls_datasets[\"CLINTOX\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"train_batch_size\": 16,\n",
        "    \"learning_rate\": 1.82e-5,\n",
        "    \"weight_decay\": 0.4,\n",
        "    \"warmup_ratio\": 0.2\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs-1FmBkP2Zg"
      },
      "outputs": [],
      "source": [
        "# setting configurations according to the hyperparameter search analysis for regression tasks\n",
        "\n",
        "\n",
        "reg_datasets[\"LIPO\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 2.48e-5,\n",
        "    \"weight_decay\": 0.4,\n",
        "    \"warmup_ratio\": 0.1\n",
        "    }\n",
        "\n",
        "\n",
        "reg_datasets[\"ESOL\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 20,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 2.85e-5,\n",
        "    \"weight_decay\": 0.4,\n",
        "    \"warmup_ratio\": 0.3\n",
        "    }\n",
        "\n",
        "\n",
        "reg_datasets[\"FreeSolv\"][\"config\"] = {\n",
        "    \"num_train_epochs\": 50,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"learning_rate\": 2.96e-5,\n",
        "    \"weight_decay\": 0.1,\n",
        "    \"warmup_ratio\": 0.2\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkEwS0Q7Ye0i"
      },
      "outputs": [],
      "source": [
        "def finetune(splits, task_type, model_name=None, project_name=\"My Project\"):\n",
        "    '''\n",
        "    This function runs the fine-tuning loop for a given set\n",
        "    of datasets and a task type (regression or classification).\n",
        "    It iterates through each task, initializes a model, sets up\n",
        "    training arguments and trains the model using HuggingFace's\n",
        "    Trainer API. After training, it evaluates the model on the\n",
        "    validation and test sets, stores the results, and saves the\n",
        "    fine-tuned model.\n",
        "\n",
        "    task type: \"reg\" - regression or \"cls\" - classification\n",
        "    model_name: the name of the model to use for training. If None,\n",
        "                the default model will be used.\n",
        "    project_name: the name of the wandb project to use for logging.\n",
        "    '''\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if model_name is None:\n",
        "        model_name = \"ibm/MoLFormer-XL-both-10pct\"\n",
        "\n",
        "    for task_name, splits in splits.items():\n",
        "    # task_name corresponds to the property/task that we are fine-tuning for\n",
        "    # splits is the train, eval, and test datasets for each task\n",
        "\n",
        "        # printing display\n",
        "        width = 70\n",
        "        print(\"\\n\" + \"-\" * width)\n",
        "        print(f\" Fine-tuning task: {task_name} \".center(width, \"-\"))\n",
        "        print(f\" Type: {task_type.upper()} \".center(width, \"-\"))\n",
        "        print(\"-\" * width)\n",
        "\n",
        "        # creating a folder for each task\n",
        "        task_output_dir = f\"/content/FinetunedModels/{task_name}\"\n",
        "        os.makedirs(task_output_dir, exist_ok=True)\n",
        "\n",
        "        # extracting task-dependent variables\n",
        "        num_labels = splits[\"train\"].get_num_classes()\n",
        "        config = splits[\"config\"]\n",
        "        train_dataset = splits[\"train\"]\n",
        "        eval_dataset = splits[\"eval\"]\n",
        "        test_dataset = splits[\"test\"]\n",
        "\n",
        "        if task_type == \"cls\":\n",
        "          metric_key = \"roc_auc\"\n",
        "        elif task_type == \"reg\":\n",
        "          metric_key = \"rmse\"\n",
        "        else:\n",
        "          raise ValueError(\n",
        "              f\"Unknown task type: {task_type}. \"\n",
        "              \"Please use 'cls' for classification or 'reg' for regression.\"\n",
        "          )\n",
        "\n",
        "        # initializing a fresh model per dataset\n",
        "        model = CustomModelForSequenceClassification(model_name, num_labels)\n",
        "\n",
        "        # training args per task\n",
        "        task_training_args = get_training_args(output_dir=task_output_dir,\n",
        "                                               task_type=task_type,\n",
        "                                               best_metric=metric_key,\n",
        "                                               config=config)\n",
        "\n",
        "        # according to HF's Trainer API\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=task_training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            compute_metrics=compute_metrics,  # custom metric function per task\n",
        "          )\n",
        "\n",
        "        run = wandb.init(\n",
        "            project=project_name,\n",
        "            name=f\"finetune-{task_name}\",\n",
        "            reinit=True\n",
        "          )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        # evaluating on validation and test set\n",
        "        # a dictionary of metrics per dataset\n",
        "        metrics_val = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "        metrics_test = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "        # extracting the specific metric from the dictionary,\n",
        "        # based on the task ('eval_roc_auc' or 'eval_rmse')\n",
        "        eval_key = f\"eval_{metric_key}\"\n",
        "        val_score = metrics_val.get(eval_key, 0.0)\n",
        "        test_score = metrics_test.get(eval_key, 0.0)\n",
        "\n",
        "        # storing in results\n",
        "        results[task_name] = {\n",
        "          f\"val_{metric_key}\": val_score,\n",
        "          f\"test_{metric_key}\": test_score,\n",
        "          \"task_type\": task_type\n",
        "          }\n",
        "\n",
        "        print(f\"[{task_name}] {metric_key.upper()}: VAL - {val_score:.4f} | TEST - {test_score:.4f}\")\n",
        "\n",
        "        # saving the best model checkpoints\n",
        "        shutil.make_archive(f\"/content/{task_name}_best_model\", \"zip\", trainer.state.best_model_checkpoint)\n",
        "\n",
        "        run.finish()\n",
        "\n",
        "    print(\"All results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iq6t66gQc0Jr"
      },
      "outputs": [],
      "source": [
        "# fine-tuning for classification tasks after hyper parameter search\n",
        "# note: the project name is just an example\n",
        "\n",
        "finetune(cls_datasets, \"cls\", project_name=\"finetuning-post-hp-search-cls-tasks-20-epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX5wAOg6SPfy",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# fine-tuning for regression tasks after hyper parameter search\n",
        "# note: the project name is just an example\n",
        "\n",
        "finetune(reg_datasets, \"reg\", project_name=\"finetuning-post-hp-search-reg-tasks-20-epochs\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2026.01"
      },
      "provenance": [],
      "collapsed_sections": [
        "--A-t0q21lmY",
        "R5SlIdyX5w9Q",
        "qagqb3Fz6bz8"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}